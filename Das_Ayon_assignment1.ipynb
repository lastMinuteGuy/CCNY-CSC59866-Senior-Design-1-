{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e2BHZJFpYdXz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Part A: Model Code\n",
        "# 1. Euclidean Distance\n",
        "def euclidean_distance(vector1, vector2):\n",
        "    return np.sqrt(np.sum((vector1 - vector2) ** 2))\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Manhattan Distance\n",
        "def manhattan_distance(vector1, vector2):\n",
        "    return np.sum(np.abs(vector1 - vector2))\n"
      ],
      "metadata": {
        "id": "b07XGdaXYhcY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Accuracy and Generalization Error\n",
        "def accuracy(y_true, y_pred):\n",
        "    return np.mean(y_true == y_pred)\n",
        "\n",
        "def generalization_error(y_true, y_pred):\n",
        "    return 1 - accuracy(y_true, y_pred)\n"
      ],
      "metadata": {
        "id": "xLzCl4KFYhnM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Precision, Recall, and F1 Score\n",
        "def precision(y_true, y_pred):\n",
        "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
        "    return tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
        "    return tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    prec = precision(y_true, y_pred)\n",
        "    rec = recall(y_true, y_pred)\n",
        "    return 2 * (prec * rec) / (prec + rec) if (prec + rec) > 0 else 0\n"
      ],
      "metadata": {
        "id": "NdzPLK4EYhwM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Confusion Matrix\n",
        "def confusion_matrix(y_true, y_pred):\n",
        "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
        "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
        "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
        "    return np.array([[tn, fp], [fn, tp]])\n"
      ],
      "metadata": {
        "id": "AFiGisORYh3n"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 6. ROC Curve\n",
        "def roc_curve(y_true, y_score):\n",
        "    # This is a placeholder\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "R05_5T46Yh8e"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. AUC for ROC Curve\n",
        "def auc(fpr, tpr):\n",
        "    # This is a placeholder\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "OcpdMoHZYh-i"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Precision-Recall Curve\n",
        "def precision_recall_curve(y_true, y_score):\n",
        "    # This is a placeholder\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "Mbq24byXYiCs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. KNN_Classifier Model Class\n",
        "class KNN_Classifier:\n",
        "    def __init__(self):\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "        self.n_neighbors = None\n",
        "        self.weights = 'uniform'\n",
        "\n",
        "    def fit(self, X, Y, n_neighbors=5, weights='uniform'):\n",
        "        self.X_train = X\n",
        "        self.y_train = Y\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.weights = weights\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Placeholder for prediction logic\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "XYds9Zd3YiEE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Part B: Data Processing\n",
        "\n",
        "# 10. Reading the winequality-white.csv file as a Pandas data frame.\n",
        "df = pd.read_csv('winequality-white.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "xYg6L2AjYiH8",
        "outputId": "acfee00b-5221-4913-b20d-9c76f8207740"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'winequality-white.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d6310f688a11>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 10. Reading the winequality-white.csv file as a Pandas data frame.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'winequality-white.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'winequality-white.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Convert quality into binary classification\n",
        "df['quality'] = df['quality'].apply(lambda x: 1 if x > 5 else 0)\n"
      ],
      "metadata": {
        "id": "k-u4Z0iAY1US"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Summarizing each of the variables in terms of mean, standard deviation, and quartiles.\n",
        "summary = df.describe()\n"
      ],
      "metadata": {
        "id": "DBCdhq-sY1dT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 13. Shuffling the rows of your data.\n",
        "df_shuffled = df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "gAr10w41Y1oR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 14. Generating pair plots to identify redundant features.\n",
        "import seaborn as sns\n",
        "    #sns.pairplot(df_shuffled)\n",
        "\n"
      ],
      "metadata": {
        "id": "sC6ofBBKY9vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 15. Drop the redundant features identified from the pair plots.\n",
        "df_shuffled = df_shuffled.drop(columns=['redundant_feature1', 'redundant_feature2'])\n"
      ],
      "metadata": {
        "id": "LPx21rxoY9xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 16. Partition function to split data into training and test sets.\n",
        "def partition(X, Y, t):\n",
        "    train_size = int((1 - t) * X.shape[0])\n",
        "    return X[:train_size], X[train_size:], Y[:train_size], Y[train_size:]\n",
        "\n",
        "# Splitting the dataset\n",
        "X = df_shuffled.drop('quality', axis=1).values\n",
        "Y = df_shuffled['quality'].values\n",
        "X_train, X_test, Y_train, Y_test = partition(X, Y, t=0.2)\n"
      ],
      "metadata": {
        "id": "LddpEcgHY91b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part C: Model Evaluation\n",
        "# Implement a basic KNN classifier\n",
        "\n",
        "class KNN_Classifier:\n",
        "    def __init__(self):\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "        self.n_neighbors = None\n",
        "        self.weights = None\n",
        "\n",
        "    def fit(self, X, Y, n_neighbors=5, weights='uniform'):\n",
        "        self.X_train = X\n",
        "        self.y_train = Y\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.weights = weights\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for i in range(X.shape[0]):\n",
        "            # Compute distances from X[i] to all points in self.X_train\n",
        "            distances = np.sqrt(np.sum((self.X_train - X[i]) ** 2, axis=1))\n",
        "\n",
        "            # Sort distances, and return the indices of k nearest neighbors\n",
        "            k_indices = np.argsort(distances)[:self.n_neighbors]\n",
        "\n",
        "            # Extract the labels of the nearest neighbors\n",
        "            k_nearest_labels = self.y_train[k_indices]\n",
        "\n",
        "            # For 'uniform' weights, use majority vote\n",
        "            if self.weights == 'uniform':\n",
        "                # Count occurrences of each class in the nearest neighbors\n",
        "                counts = np.bincount(k_nearest_labels)\n",
        "                # Choose the class with the most occurrences\n",
        "                predictions.append(counts.argmax())\n",
        "\n",
        "            # For 'distance' weights, weight votes by inverse distance\n",
        "            elif self.weights == 'distance':\n",
        "                # Count occurrences of each class, weighted by inverse distance\n",
        "                weights = 1 / distances[k_indices]\n",
        "                prediction = np.argmax(np.bincount(k_nearest_labels, weights=weights))\n",
        "                predictions.append(prediction)\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n",
        "# Instantiate the classifier\n",
        "knn = KNN_Classifier()\n",
        "\n",
        "# Fit the model on the training data\n",
        "knn.fit(X_train, Y_train, n_neighbors=5, weights='uniform')\n",
        "\n",
        "# Make predictions on the test data\n",
        "Y_pred = knn.predict(X_test)\n",
        "\n",
        "# Calculate accuracy, precision, recall, F1 score, confusion matrix, etc.\n",
        "accuracy_val = accuracy(Y_test, Y_pred)\n",
        "precision_val = precision(Y_test, Y_pred)\n",
        "recall_val = recall(Y_test, Y_pred)\n",
        "f1_val = f1_score(Y_test, Y_pred)\n",
        "conf_matrix = confusion_matrix(Y_test, Y_pred)\n"
      ],
      "metadata": {
        "id": "rqvwPpnCY927"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xv8NVpKWY96z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VnAoAPjcY-En"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}